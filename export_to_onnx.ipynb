{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeMUpQxDQF92",
        "outputId": "93988a78-286f-40ea-d343-eda729f14ba5"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# !pip3 install onnx\n",
        "import onnx\n",
        "# !pip3 install onnx-simplifier\n",
        "import onnxsim\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "U1rJ8E-YQF93"
      },
      "outputs": [],
      "source": [
        "class SuperPointNet(torch.nn.Module):\n",
        "  \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
        "  def __init__(self):\n",
        "    super(SuperPointNet, self).__init__()\n",
        "    self.relu = torch.nn.ReLU(inplace=True)\n",
        "    self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
        "    # Shared Encoder.\n",
        "    self.conv1a = torch.nn.Conv2d(1, c1, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv1b = torch.nn.Conv2d(c1, c1, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2a = torch.nn.Conv2d(c1, c2, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv2b = torch.nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3a = torch.nn.Conv2d(c2, c3, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv3b = torch.nn.Conv2d(c3, c3, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv4a = torch.nn.Conv2d(c3, c4, kernel_size=3, stride=1, padding=1)\n",
        "    self.conv4b = torch.nn.Conv2d(c4, c4, kernel_size=3, stride=1, padding=1)\n",
        "    # Detector Head.\n",
        "    self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "    self.convPb = torch.nn.Conv2d(c5, 65, kernel_size=1, stride=1, padding=0)\n",
        "    # Descriptor Head.\n",
        "    self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "    self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
        "\n",
        "  def forward(self, x):\n",
        "    \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
        "    tensors.\n",
        "    Input\n",
        "      x: Image pytorch tensor shaped N x 1 x H x W.\n",
        "    Output\n",
        "      semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
        "      desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
        "    \"\"\"\n",
        "    # Shared Encoder.\n",
        "    x = self.relu(self.conv1a(x))\n",
        "    x = self.relu(self.conv1b(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.relu(self.conv2a(x))\n",
        "    x = self.relu(self.conv2b(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.relu(self.conv3a(x))\n",
        "    x = self.relu(self.conv3b(x))\n",
        "    x = self.pool(x)\n",
        "    x = self.relu(self.conv4a(x))\n",
        "    x = self.relu(self.conv4b(x))\n",
        "    # Detector Head.\n",
        "    cPa = self.relu(self.convPa(x))\n",
        "    semi = self.convPb(cPa)\n",
        "    # Descriptor Head.\n",
        "    cDa = self.relu(self.convDa(x))\n",
        "    desc = self.convDb(cDa)\n",
        "    dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
        "    desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
        "    return semi, desc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q0f-nBylt8Vg",
        "outputId": "7d70d4c8-1a4a-4a87-8b1a-b9b8320922a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1300865"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SuperPointNet()\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "num_params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "sN126S_CfFWo"
      },
      "outputs": [],
      "source": [
        "class double_conv(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(double_conv, self).__init__()\n",
        "\n",
        "        def conv_dw(inp, oup, stride):\n",
        "            return nn.Sequential(\n",
        "                nn.Conv2d(inp, inp, 3, stride, 1, groups=inp, bias=False),\n",
        "                nn.BatchNorm2d(inp),\n",
        "                nn.ReLU(inplace=True),\n",
        "\n",
        "                nn.Conv2d(inp, oup, 1, 1, 0, bias=False),\n",
        "                nn.BatchNorm2d(oup),\n",
        "                nn.ReLU(inplace=True),\n",
        "            )\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "        # Mobilenet v1\n",
        "        # self.conv = nn.Sequential(\n",
        "        #     conv_dw(in_ch, out_ch, 1),\n",
        "        #     nn.BatchNorm2d(out_ch),\n",
        "        #     nn.ReLU(inplace=True),\n",
        "        #     conv_dw(out_ch, out_ch, 1),\n",
        "        #     nn.BatchNorm2d(out_ch),\n",
        "        #     nn.ReLU(inplace=True)\n",
        "        # )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class inconv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(inconv, self).__init__()\n",
        "        self.conv = double_conv(in_ch, out_ch)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class down(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch):\n",
        "        super(down, self).__init__()\n",
        "        self.mpconv = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv(in_ch, out_ch)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.mpconv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "m_30eLC8fdGI"
      },
      "outputs": [],
      "source": [
        "class SuperPointNet_gauss2(torch.nn.Module):\n",
        "    \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
        "    def __init__(self, subpixel_channel=1):\n",
        "        super(SuperPointNet_gauss2, self).__init__()\n",
        "        c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
        "        det_h = 65\n",
        "        self.inc = inconv(1, c1)\n",
        "        self.down1 = down(c1, c2)\n",
        "        self.down2 = down(c2, c3)\n",
        "        self.down3 = down(c3, c4)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "\n",
        "        # Detector Head.\n",
        "        self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnPa = nn.BatchNorm2d(c5)\n",
        "        self.convPb = torch.nn.Conv2d(c5, det_h, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnPb = nn.BatchNorm2d(det_h)\n",
        "        # Descriptor Head.\n",
        "        self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnDa = nn.BatchNorm2d(c5)\n",
        "        self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnDb = nn.BatchNorm2d(d1)\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
        "        tensors.\n",
        "        Input\n",
        "          x: Image pytorch tensor shaped N x 1 x patch_size x patch_size.\n",
        "        Output\n",
        "          semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
        "          desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
        "        \"\"\"\n",
        "        # Let's stick to this version: first BN, then relu\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "\n",
        "        # Detector Head.\n",
        "        cPa = self.relu(self.bnPa(self.convPa(x4)))\n",
        "        semi = self.bnPb(self.convPb(cPa))\n",
        "        # Descriptor Head.\n",
        "        cDa = self.relu(self.bnDa(self.convDa(x4)))\n",
        "        desc = self.bnDb(self.convDb(cDa))\n",
        "\n",
        "        dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
        "        desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
        "        output = {'semi': semi, 'desc': desc}\n",
        "        self.output = output\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "orVX7hicuXQA",
        "outputId": "12f9116e-8754-4711-e42b-f257ee4321bf"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1304067"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SuperPointNet_gauss2()\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "num_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpEUr1KLuqHA"
      },
      "source": [
        "*MobileNet v2*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "O8IXdJnjugLw"
      },
      "outputs": [],
      "source": [
        "class InvertedResidual(nn.Module):\n",
        "    def __init__(self, inp, oup, stride, expand_ratio, use_batch_norm=True, onnx_compatible=False):\n",
        "        super(InvertedResidual, self).__init__()\n",
        "        ReLU = nn.ReLU if onnx_compatible else nn.ReLU6\n",
        "\n",
        "        self.stride = stride\n",
        "        assert stride in [1, 2]\n",
        "\n",
        "        hidden_dim = round(inp * expand_ratio)\n",
        "        self.use_res_connect = self.stride == 1 and inp == oup\n",
        "\n",
        "        if expand_ratio == 1:\n",
        "            if use_batch_norm:\n",
        "                self.conv = nn.Sequential(\n",
        "                    # dw\n",
        "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                    nn.BatchNorm2d(hidden_dim),\n",
        "                    ReLU(inplace=True),\n",
        "                    # pw-linear\n",
        "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                    nn.BatchNorm2d(oup),\n",
        "                )\n",
        "            else:\n",
        "                self.conv = nn.Sequential(\n",
        "                    # dw\n",
        "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                    ReLU(inplace=True),\n",
        "                    # pw-linear\n",
        "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                )\n",
        "        else:\n",
        "            if use_batch_norm:\n",
        "                self.conv = nn.Sequential(\n",
        "                    # pw\n",
        "                    nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                    nn.BatchNorm2d(hidden_dim),\n",
        "                    ReLU(inplace=True),\n",
        "                    # dw\n",
        "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                    nn.BatchNorm2d(hidden_dim),\n",
        "                    ReLU(inplace=True),\n",
        "                    # pw-linear\n",
        "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                    nn.BatchNorm2d(oup),\n",
        "                )\n",
        "            else:\n",
        "                self.conv = nn.Sequential(\n",
        "                    # pw\n",
        "                    nn.Conv2d(inp, hidden_dim, 1, 1, 0, bias=False),\n",
        "                    ReLU(inplace=True),\n",
        "                    # dw\n",
        "                    nn.Conv2d(hidden_dim, hidden_dim, 3, stride, 1, groups=hidden_dim, bias=False),\n",
        "                    ReLU(inplace=True),\n",
        "                    # pw-linear\n",
        "                    nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
        "                )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_res_connect:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "\n",
        "\n",
        "class double_conv_mobilenet(nn.Module):\n",
        "    '''(conv => BN => ReLU) * 2'''\n",
        "    def __init__(self, in_ch, out_ch, expand_ratio):\n",
        "        super(double_conv_mobilenet, self).__init__()\n",
        "\n",
        "        # Mobilenet v2\n",
        "        self.conv = nn.Sequential(\n",
        "            InvertedResidual(in_ch, out_ch, 1, expand_ratio=expand_ratio, use_batch_norm=True, onnx_compatible=True),\n",
        "            nn.ReLU(inplace=True),\n",
        "            InvertedResidual(out_ch, out_ch, 1, expand_ratio=expand_ratio, use_batch_norm=True, onnx_compatible=True),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9S2pAxThurIv"
      },
      "outputs": [],
      "source": [
        "class SuperPointNet_mobilenet(torch.nn.Module):\n",
        "    \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
        "    def __init__(self, subpixel_channel=1):\n",
        "        super(SuperPointNet_mobilenet, self).__init__()\n",
        "        c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
        "        det_h = 65\n",
        "        self.inc = double_conv_mobilenet(1, c1, expand_ratio=1)\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv_mobilenet(c1, c2, expand_ratio=2)\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv_mobilenet(c2, c3, expand_ratio=2)\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            double_conv_mobilenet(c3, c4, expand_ratio=2)\n",
        "        )\n",
        "\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        # Detector Head.\n",
        "        self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnPa = nn.BatchNorm2d(c5)\n",
        "        self.convPb = torch.nn.Conv2d(c5, det_h, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnPb = nn.BatchNorm2d(det_h)\n",
        "        # Descriptor Head.\n",
        "        self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnDa = nn.BatchNorm2d(c5)\n",
        "        self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnDb = nn.BatchNorm2d(d1)\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
        "        tensors.\n",
        "        Input\n",
        "          x: Image pytorch tensor shaped N x 1 x patch_size x patch_size.\n",
        "        Output\n",
        "          semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
        "          desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
        "        \"\"\"\n",
        "        # Let's stick to this version: first BN, then relu\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "\n",
        "        # Detector Head.\n",
        "        cPa = self.relu(self.bnPa(self.convPa(x4)))\n",
        "        semi = self.bnPb(self.convPb(cPa))\n",
        "        # Descriptor Head.\n",
        "        cDa = self.relu(self.bnDa(self.convDa(x4)))\n",
        "        desc = self.bnDb(self.convDb(cDa))\n",
        "\n",
        "        dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
        "        desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
        "        output = {'semi': semi, 'desc': desc}\n",
        "        self.output = output\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctdievmhwaNE",
        "outputId": "fab56520-ae8f-402f-ea09-083895e9a8fa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "949838"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SuperPointNet_mobilenet()\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "num_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFiR8ZVrwa1Y"
      },
      "source": [
        "SqueezeNet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Jhr28WAuwfj7"
      },
      "outputs": [],
      "source": [
        "class Fire(nn.Module):\n",
        "\n",
        "    def __init__(self, inplanes, squeeze_planes,\n",
        "                 expand1x1_planes, expand3x3_planes):\n",
        "        super(Fire, self).__init__()\n",
        "        self.inplanes = inplanes\n",
        "        self.squeeze = nn.Conv2d(inplanes, squeeze_planes, kernel_size=1)\n",
        "        self.squeeze_bn = nn.BatchNorm2d(squeeze_planes)\n",
        "        self.squeeze_activation = nn.ReLU(inplace=True)\n",
        "        self.expand1x1 = nn.Conv2d(squeeze_planes, expand1x1_planes,\n",
        "                                   kernel_size=1)\n",
        "        self.expand1x1_bn = nn.BatchNorm2d(expand1x1_planes)\n",
        "        self.expand1x1_activation = nn.ReLU(inplace=True)\n",
        "        self.expand3x3 = nn.Conv2d(squeeze_planes, expand3x3_planes,\n",
        "                                   kernel_size=3, padding=1)\n",
        "        self.expand3x3_bn = nn.BatchNorm2d(expand3x3_planes)\n",
        "        self.expand3x3_activation = nn.ReLU(inplace=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.squeeze_activation(self.squeeze_bn(self.squeeze(x)))\n",
        "        return torch.cat([\n",
        "            self.expand1x1_activation(self.expand1x1_bn(self.expand1x1(x))),\n",
        "            self.expand3x3_activation(self.expand3x3_bn(self.expand3x3(x)))\n",
        "        ], 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JRurRv7XwlFR"
      },
      "outputs": [],
      "source": [
        "class SuperPointNet_squeezenet(torch.nn.Module):\n",
        "    \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
        "    def __init__(self, subpixel_channel=1):\n",
        "        super(SuperPointNet_squeezenet, self).__init__()\n",
        "        c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
        "        det_h = 65\n",
        "        self.inc = nn.Sequential(\n",
        "            nn.Conv2d(1, c1, 3, padding=1),\n",
        "            nn.BatchNorm2d(c1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(c1, c1, 3, padding=1),\n",
        "            nn.BatchNorm2d(c1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.down1 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            Fire(c1, 16, int(c2/2), int(c2/2)),\n",
        "            Fire(c2, 16, int(c2/2), int(c2/2)),\n",
        "        )\n",
        "        self.down2 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            Fire(c2, 32, int(c3/2), int(c3/2)),\n",
        "            Fire(c3, 32, int(c3/2), int(c3/2)),\n",
        "        )\n",
        "        self.down3 = nn.Sequential(\n",
        "            nn.MaxPool2d(2),\n",
        "            Fire(c3, 48, int(c4/2), int(c4/2)),\n",
        "            Fire(c4, 48, int(c4/2), int(c4/2)),\n",
        "        )\n",
        "\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        # Detector Head.\n",
        "        self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnPa = nn.BatchNorm2d(c5)\n",
        "        self.convPb = torch.nn.Conv2d(c5, det_h, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnPb = nn.BatchNorm2d(det_h)\n",
        "        # Descriptor Head.\n",
        "        self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnDa = nn.BatchNorm2d(c5)\n",
        "        self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnDb = nn.BatchNorm2d(d1)\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
        "        tensors.\n",
        "        Input\n",
        "          x: Image pytorch tensor shaped N x 1 x patch_size x patch_size.\n",
        "        Output\n",
        "          semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
        "          desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
        "        \"\"\"\n",
        "        # Let's stick to this version: first BN, then relu\n",
        "        x1 = self.inc(x)\n",
        "        x2 = self.down1(x1)\n",
        "        x3 = self.down2(x2)\n",
        "        x4 = self.down3(x3)\n",
        "\n",
        "        # Detector Head.\n",
        "        cPa = self.relu(self.bnPa(self.convPa(x4)))\n",
        "        semi = self.bnPb(self.convPb(cPa))\n",
        "        # Descriptor Head.\n",
        "        cDa = self.relu(self.bnDa(self.convDa(x4)))\n",
        "        desc = self.bnDb(self.convDb(cDa))\n",
        "\n",
        "        dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
        "        desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
        "        output = {'semi': semi, 'desc': desc}\n",
        "        self.output = output\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ruFMd8vSu7-f",
        "outputId": "b80ca875-ae15-4319-de2e-4c2f473c7009"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "847939"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SuperPointNet_squeezenet()\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "num_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Resnet18"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {},
      "outputs": [],
      "source": [
        "from models.resnet import resnet18\n",
        "\n",
        "# from models.SubpixelNet import SubpixelNet\n",
        "class SuperPointNet_resnet18(torch.nn.Module):\n",
        "    \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
        "    def __init__(self, subpixel_channel=1):\n",
        "        super(SuperPointNet_resnet18, self).__init__()\n",
        "        c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
        "        det_h = 65\n",
        "        self.feature = resnet18()\n",
        "        # self.inc = inconv(1, c1)\n",
        "        # self.down1 = down(c1, c2)\n",
        "        # self.down2 = down(c2, c3)\n",
        "        # self.down3 = down(c3, c4)\n",
        "        # self.down4 = down(c4, 512)\n",
        "        # self.up1 = up(c4+c3, c2)\n",
        "        # self.up2 = up(c2+c2, c1)\n",
        "        # self.up3 = up(c1+c1, c1)\n",
        "        # self.outc = outconv(c1, subpixel_channel)\n",
        "        self.relu = torch.nn.ReLU(inplace=True)\n",
        "        # self.outc = outconv(64, n_classes)\n",
        "        # Detector Head.\n",
        "        self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnPa = nn.BatchNorm2d(c5)\n",
        "        self.convPb = torch.nn.Conv2d(c5, det_h, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnPb = nn.BatchNorm2d(det_h)\n",
        "        # Descriptor Head.\n",
        "        self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
        "        self.bnDa = nn.BatchNorm2d(c5)\n",
        "        self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
        "        self.bnDb = nn.BatchNorm2d(d1)\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
        "        tensors.\n",
        "        Input\n",
        "          x: Image pytorch tensor shaped N x 1 x patch_size x patch_size.\n",
        "        Output\n",
        "          semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
        "          desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
        "        \"\"\"\n",
        "        # Let's stick to this version: first BN, then relu\n",
        "        # x1 = self.inc(x)\n",
        "        # x2 = self.down1(x1)\n",
        "        # x3 = self.down2(x2)\n",
        "        # x4 = self.down3(x3)\n",
        "        x4 = self.feature(x)\n",
        "\n",
        "        # Detector Head.\n",
        "        cPa = self.relu(self.bnPa(self.convPa(x4)))\n",
        "        semi = self.bnPb(self.convPb(cPa))\n",
        "        # Descriptor Head.\n",
        "        cDa = self.relu(self.bnDa(self.convDa(x4)))\n",
        "        desc = self.bnDb(self.convDb(cDa))\n",
        "\n",
        "        dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
        "        desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
        "        output = {'semi': semi, 'desc': desc}\n",
        "        self.output = output\n",
        "\n",
        "        return output\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1942147"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SuperPointNet_resnet18()\n",
        "num_params = sum([np.prod(p.size()) for p in model.parameters()])\n",
        "num_params"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQ7U0iL9vLvf"
      },
      "source": [
        "Export to onnx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "zJBLFWQDQF93",
        "outputId": "c392b624-50a5-4542-caba-7955e915e8b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net1 = SuperPointNet()\n",
        "state_dict1 = torch.load('./pretrained/superpoint_v1.pth')\n",
        "net1.load_state_dict(state_dict1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h8c8tKKfqqD",
        "outputId": "06b3aa04-db2c-4289-e148-0b7cea15b80b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SuperPointNet_gauss2(\n",
              "  (inc): inconv(\n",
              "    (conv): double_conv(\n",
              "      (conv): Sequential(\n",
              "        (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (2): ReLU(inplace=True)\n",
              "        (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "        (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (5): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down1): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): down(\n",
              "    (mpconv): Sequential(\n",
              "      (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "      (1): double_conv(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (5): ReLU(inplace=True)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (convPa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnPa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convPb): Conv2d(256, 65, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnPb): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnDa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDb): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnDb): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = SuperPointNet_gauss2()\n",
        "checkpoint = torch.load('./logs/superpoint_coco_gauss/checkpoints/superPointNet_150000_checkpoint.pth.tar', map_location=torch.device('cpu'))\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SuperPointNet_mobilenet(\n",
              "  (inc): double_conv_mobilenet(\n",
              "    (conv): Sequential(\n",
              "      (0): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "          (1): BatchNorm2d(1, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(1, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): ReLU(inplace=True)\n",
              "      (2): InvertedResidual(\n",
              "        (conv): Sequential(\n",
              "          (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
              "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          (2): ReLU(inplace=True)\n",
              "          (3): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (3): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down1): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): double_conv_mobilenet(\n",
              "      (conv): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "            (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): InvertedResidual(\n",
              "          (conv): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "            (6): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down2): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): double_conv_mobilenet(\n",
              "      (conv): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv): Sequential(\n",
              "            (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)\n",
              "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "            (6): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): InvertedResidual(\n",
              "          (conv): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "            (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (down3): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): double_conv_mobilenet(\n",
              "      (conv): Sequential(\n",
              "        (0): InvertedResidual(\n",
              "          (conv): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "            (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (1): ReLU(inplace=True)\n",
              "        (2): InvertedResidual(\n",
              "          (conv): Sequential(\n",
              "            (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
              "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "            (5): ReLU(inplace=True)\n",
              "            (6): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "            (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "          )\n",
              "        )\n",
              "        (3): ReLU(inplace=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (convPa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnPa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convPb): Conv2d(256, 65, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnPb): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnDa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDb): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnDb): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = SuperPointNet_mobilenet()\n",
        "checkpoint = torch.load('./logs/superpoint_coco_mobilenet_v2/checkpoints/superPointNet_150000_checkpoint.pth.tar', map_location=torch.device('cpu'))\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SuperPointNet_squeezenet(\n",
              "  (inc): Sequential(\n",
              "    (0): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): ReLU(inplace=True)\n",
              "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (5): ReLU(inplace=True)\n",
              "  )\n",
              "  (down1): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Fire(\n",
              "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Fire(\n",
              "      (squeeze): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down2): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Fire(\n",
              "      (squeeze): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Fire(\n",
              "      (squeeze): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (down3): Sequential(\n",
              "    (0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (1): Fire(\n",
              "      (squeeze): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "    (2): Fire(\n",
              "      (squeeze): Conv2d(128, 48, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (squeeze_bn): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (squeeze_activation): ReLU(inplace=True)\n",
              "      (expand1x1): Conv2d(48, 64, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (expand1x1_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand1x1_activation): ReLU(inplace=True)\n",
              "      (expand3x3): Conv2d(48, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      (expand3x3_bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (expand3x3_activation): ReLU(inplace=True)\n",
              "    )\n",
              "  )\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (convPa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnPa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convPb): Conv2d(256, 65, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnPb): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnDa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDb): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnDb): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = SuperPointNet_squeezenet()\n",
        "checkpoint = torch.load('./logs/superpoint_coco_squeezenet/checkpoints/superPointNet_150000_checkpoint.pth.tar', map_location=torch.device('cpu'))\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SuperPointNet_resnet18(\n",
              "  (feature): ResNet(\n",
              "    (conv1): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (relu): ReLU(inplace=True)\n",
              "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    (layer1): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer2): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (downsample): Sequential(\n",
              "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        )\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "    (layer3): Sequential(\n",
              "      (0): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "      (1): BasicBlock(\n",
              "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (relu): ReLU(inplace=True)\n",
              "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (relu): ReLU(inplace=True)\n",
              "  (convPa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnPa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convPb): Conv2d(256, 65, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnPb): BatchNorm2d(65, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDa): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "  (bnDa): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  (convDb): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "  (bnDb): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              ")"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "net = SuperPointNet_resnet18()\n",
        "checkpoint = torch.load('./logs/superpoint_coco_resnet18/checkpoints/superPointNet_150000_checkpoint.pth.tar', map_location=torch.device('cpu'))\n",
        "net.load_state_dict(checkpoint['model_state_dict'])\n",
        "net.eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XacmtmRQF94",
        "outputId": "c718b1d9-7fbd-4f03-e8d2-feb91fca9fd2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7.1143, 7.1408, 7.4010, 7.3743, 7.1654, 7.0392, 6.9852, 6.8115, 6.7343,\n",
              "        6.6291, 6.5956, 6.5610, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692,\n",
              "        6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692,\n",
              "        6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692,\n",
              "        6.5692, 6.5692, 6.5541, 6.5457, 6.5599, 6.6784, 6.8644, 7.1354, 7.3488,\n",
              "        7.6130, 7.8650, 7.4608, 6.3813], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x = torch.ones(1, 1, 120, 392, requires_grad=True)\n",
        "torch_out = net(x)\n",
        "torch_out['semi'][0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "pFzz5MdEQF95"
      },
      "outputs": [],
      "source": [
        "torch.onnx.export(net,               # model being run\n",
        "                  x,                         # model input (or a tuple for multiple inputs)\n",
        "                  \"sp_resnet18_b1.onnx\",   # where to save the model (can be a file or file-like object)\n",
        "                  export_params=True,        # store the trained parameter weights inside the model file\n",
        "                  opset_version=11,          # the ONNX version to export the model to\n",
        "                  training = torch.onnx.TrainingMode.EVAL,\n",
        "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
        "                  input_names = ['input'],   # the model's input names\n",
        "                  output_names = ['output_det', 'output_desc'],\n",
        "                  dynamic_axes={\n",
        "                      \"input\":{\n",
        "                          2: \"Height\",\n",
        "                          3: \"Width\"\n",
        "                      }\n",
        "                  }\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "p-get8nBQF95"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Checks\n",
        "model_onnx = onnx.load(\"sp_resnet18_b1.onnx\")  # load onnx model\n",
        "onnx.checker.check_model(model_onnx)  # check onnx model\n",
        "# print(onnx.helper.printable_graph(model_onnx.graph))  # print"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "t5fFsZkjQF95"
      },
      "outputs": [],
      "source": [
        "model_onnx_simplified, check = onnxsim.simplify(\n",
        "    model_onnx,\n",
        "    dynamic_input_shape=True,\n",
        "    input_shapes={'input': [1,1,120,392]})\n",
        "assert check, 'assert check failed'\n",
        "onnx.save(model_onnx_simplified, \"sp_resnet18_b1_simplified.onnx\")\n",
        "\n",
        "# model_onnx, check = onnxsim.simplify(\n",
        "#     model_onnx,\n",
        "#     dynamic_input_shape=False)\n",
        "# assert check, 'assert check failed'\n",
        "# onnx.save(model_onnx, \"superpoint_pretrained_b2.onnx\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "asM3qZ1HQF95"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.5.4'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import cv2\n",
        "cv2.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "U1VH3ciKQF96",
        "outputId": "811283f9-f4f1-41cd-e34b-a2a426a22aa8"
      },
      "outputs": [],
      "source": [
        "# superpoint = cv2.dnn.readNetFromONNX(\"./onnx/sp-gauss-sparse-loss/superpoint_gauss_sparse_loss_simplified.onnx\")\n",
        "# superpoint = cv2.dnn.readNetFromONNX(\"./onnx/sp-gauss-sparse-loss/superpoint_pretrained_b1.onnx\")\n",
        "superpoint = cv2.dnn.readNetFromONNX(\"./sp_resnet18_b1_simplified.onnx\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "dLJsEAm6QF96"
      },
      "outputs": [],
      "source": [
        "img = np.ones((120, 392), dtype=np.float32)\n",
        "# img = cv2.imread(\"assets/icl_snippet/250.png\",cv2.IMREAD_GRAYSCALE)\n",
        "# img = cv2.imread(\"image_00/data/0000000010.png\", cv2.IMREAD_GRAYSCALE)\n",
        "img = cv2.resize(img, (392, 120)).astype(np.float32)\n",
        "blob = cv2.dnn.blobFromImage(img, size=(392, 120))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "3xXdfuL4QF96",
        "outputId": "c8f2b6cf-103f-4052-811c-1340db1ec6da"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img[:5, :5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "yI2Oi4bcQF96",
        "outputId": "bd300d21-6383-46fe-9b80-15b522df41d7"
      },
      "outputs": [],
      "source": [
        "superpoint.setInput(blob)\n",
        "result = superpoint.forward(superpoint.getUnconnectedOutLayersNames())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "ezQF7yXuQF97",
        "outputId": "bbb83bec-38ec-4be1-8b2e-8c420873dc6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([7.114337 , 7.1408205, 7.401045 , 7.374346 , 7.1654186, 7.0391836,\n",
              "       6.985178 , 6.8115234, 6.734315 , 6.6291046, 6.5956297, 6.5609856,\n",
              "       6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776,\n",
              "       6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776,\n",
              "       6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776,\n",
              "       6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776, 6.5691776,\n",
              "       6.5691776, 6.5691776, 6.554138 , 6.545664 , 6.559906 , 6.678446 ,\n",
              "       6.8643665, 7.1353664, 7.3487816, 7.6130466, 7.8649883, 7.4607544,\n",
              "       6.381258 ], dtype=float32)"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result[0][0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DWmQ1irhQF9-",
        "outputId": "aa6a0dff-ef7c-4eec-b51e-476562b92e1e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([1, 1, 120, 392])"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img_tensor = torch.Tensor(img).unsqueeze(0).unsqueeze(0)\n",
        "img_tensor.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "FGcnHB7HQF9-"
      },
      "outputs": [],
      "source": [
        "pytorch_result = net(img_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "CF3RFYoSQF9_",
        "outputId": "fe24df2c-b9ee-45df-b0cc-d89bef033990"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([-0.1762, -0.0966, -0.0629, -0.0491, -0.0465, -0.0619, -0.0619, -0.0619,\n",
              "        -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619,\n",
              "        -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619,\n",
              "        -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619,\n",
              "        -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619, -0.0619,\n",
              "        -0.0619, -0.0619, -0.0619, -0.0619, -0.0706, -0.0902, -0.1196, -0.1152,\n",
              "        -0.0064], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pytorch_result['desc'][0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([7.1143, 7.1408, 7.4010, 7.3743, 7.1654, 7.0392, 6.9852, 6.8115, 6.7343,\n",
              "        6.6291, 6.5956, 6.5610, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692,\n",
              "        6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692,\n",
              "        6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692, 6.5692,\n",
              "        6.5692, 6.5692, 6.5541, 6.5457, 6.5599, 6.6784, 6.8644, 7.1354, 7.3488,\n",
              "        7.6130, 7.8650, 7.4608, 6.3813], grad_fn=<SelectBackward0>)"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pytorch_result['semi'][0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OzzMIGhuQF9_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Copy of export.ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "bb919764aa2f1cc771c7cd722675f7c1a0b309da170fdb16a30017b7a534f235"
    },
    "kernelspec": {
      "display_name": "Python 3.7.0 64-bit ('my3.7.0': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
